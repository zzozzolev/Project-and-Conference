{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lyrics text to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_full = pd.read_table('lyrics_full.txt', header = None)\n",
    "lyrics_jamo = pd.read_table('lyrics_jamo.txt', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_full = np.array(lyrics_full[0])\n",
    "lyrics_jamo = np.array(lyrics_jamo[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_full_20_sep = []\n",
    "\n",
    "for sentence in lyrics_full:\n",
    "    if len(sentence) <= 20:\n",
    "        sep_list = list(sentence)\n",
    "        while len(sep_list) < 20:\n",
    "            sep_list.append('<eos>')\n",
    "    lyrics_full_20_sep.append(sep_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_jaeum_20_sep = []\n",
    "\n",
    "for sentence in lyrics_jamo:\n",
    "    if len(sentence) <= 20:\n",
    "        sep_list = list(sentence)\n",
    "        while len(sep_list) < 20:\n",
    "            sep_list.append('<eos>')\n",
    "    lyrics_jaeum_20_sep.append(sep_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_lyrics_20_sep = []\n",
    "\n",
    "for ls in lyrics_full_20_sep:\n",
    "    full_lyrics_20_sep += ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaeum_lyrics_20_sep = []\n",
    "\n",
    "for ls in lyrics_jaeum_20_sep:\n",
    "    jaeum_lyrics_20_sep += ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_part = full_lyrics_20_sep[:500000]\n",
    "jaeum_part = jaeum_lyrics_20_sep[:500000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lyrics one_hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import hgtk\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## full_lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_counter = collections.Counter(full_part)\n",
    "#print(full_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_count_pairs = sorted(full_counter.items(), key=lambda x: -x[1])\n",
    "#print(full_count_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_chars, _ = zip(*full_count_pairs)\n",
    "#print(full_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaeum_counter = collections.Counter(jaeum_part)\n",
    "jaeum_count_pairs = sorted(jaeum_counter.items(), key=lambda x: -x[1])\n",
    "jaeum_chars, _ = zip(*jaeum_count_pairs)\n",
    "jaeum_vocab_dict = dict(zip(jaeum_chars, range(len(jaeum_chars))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_vocab_size = len(full_chars)\n",
    "full_vocab_dict = dict(zip(full_chars[2:], range(21,len(full_chars)+21)))\n",
    "#print(full_vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = jaeum_vocab_dict.copy()\n",
    "vocab_dict.update(full_vocab_dict)\n",
    "inv_vocab = {v: k for k, v in vocab_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "interger_encoded_full_vocab_values = interger_encoded_full_vocab_values.reshape(len(interger_encoded_full_vocab_values), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_vocab_embedded = enc.fit_transform(interger_encoded_full_vocab_values).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_vocab_embedded = full_vocab_embedded.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jaeum_lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaeum_counter = collections.Counter(jaeum_lyrics_50_sep)\n",
    "#print(jaeum_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaeum_count_pairs = sorted(jaeum_counter.items(), key=lambda x: -x[1])\n",
    "#print(jaeum_count_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaeum_chars, _ = zip(*jaeum_count_pairs)\n",
    "#print(jaeum_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaeum_vocab_size = len(jaeum_chars)\n",
    "jaeum_vocab_dict = dict(zip(jaeum_chars, range(len(jaeum_chars))))\n",
    "#print(jaeum_vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "interger_encoded_jaeum_vocab_values = np.array(list(jaeum_vocab_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "interger_encoded_jaeum_vocab_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "interger_encoded_vocab_values = np.array(list(vocab_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "interger_encoded_vocab_values = interger_encoded_vocab_values.reshape(len(interger_encoded_vocab_values), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_embedded = enc.fit_transform(interger_encoded_vocab_values).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_embedded = vocab_embedded.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaeum_vocab_embedded = enc.fit_transform(interger_encoded_jaeum_vocab_values).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaeum_vocab_embedded = jaeum_vocab_embedded.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자음\n",
    "# 음절 -> 라벨 dict\n",
    "#jaeum_vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자음\n",
    "# 라벨 -> one hot vector embedding\n",
    "#jaeum_vocab_embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "seq_length = 20\n",
    "vocab_size = len(vocab_dict.keys())\n",
    "num_batches = len(full_part) / (batch_size*seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 250.0\n",
      "125 200.0\n",
      "200 125.0\n",
      "250 100.0\n",
      "500 50.0\n",
      "625 40.0\n",
      "1000 25.0\n",
      "1250 20.0\n",
      "2500 10.0\n",
      "3125 8.0\n",
      "5000 5.0\n",
      "6250 4.0\n",
      "12500 2.0\n",
      "25000 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(100,len(full_part)):\n",
    "    if len(full_part)/i%seq_length==0:\n",
    "        print(i,len(full_part)/(i*seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(chosung_data, full_data, batch_size, seq_length):\n",
    "    xdata = np.array(list(map(vocab_dict.get, chosung_data)))\n",
    "    ydata = np.array(list(map(vocab_dict.get, full_data)))\n",
    "    \n",
    "    x_reshape = xdata.reshape(batch_size, -1)\n",
    "    y_reshape = ydata.reshape(batch_size, -1)\n",
    "    \n",
    "    x_batches = np.split(x_reshape, x_reshape.shape[1]/seq_length, 1)\n",
    "    y_batches = np.split(y_reshape, y_reshape.shape[1]/seq_length, 1)\n",
    "   \n",
    "    return x_batches, y_batches\n",
    "    \n",
    "pointer = 0 \n",
    "def next_batch(x_batches, y_batches):    \n",
    "    global pointer\n",
    "    x, y = x_batches[pointer], y_batches[pointer]\n",
    "    pointer += 1\n",
    "    return x, y\n",
    "\n",
    "def reset_batch_pointer():\n",
    "    global pointer\n",
    "    pointer = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Network\n",
    "rnn_size = vocab_size\n",
    "num_layers = 3\n",
    "grad_clip = 5.\n",
    "\n",
    "\n",
    "MODEL_PATH = 'small models'\n",
    "LOGS_PATH = 'small logs'\n",
    "\n",
    "\n",
    "class chosungRNN:\n",
    "\n",
    "    def __init__(self, tf, batch_size, seq_length, vocab_size, vocab_embedded, start_learning_rate, decay_step, decay_rate, dropout_rate,is_training):\n",
    "        tf.reset_default_graph()\n",
    "        self.tf = tf\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_length = seq_length\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        # Select RNN Cell\n",
    "        unitcell = tf.nn.rnn_cell.BasicLSTMCell(rnn_size)\n",
    "        if is_training :\n",
    "            cell = tf.contrib.rnn.DropoutWrapper(unitcell, output_keep_prob= 1- dropout_rate)\n",
    "            self.cell = tf.nn.rnn_cell.MultiRNNCell([cell] * num_layers)\n",
    "        else:\n",
    "            self.cell = tf.nn.rnn_cell.MultiRNNCell([unitcell] * num_layers)\n",
    "                \n",
    "\n",
    "        # Set paths to the graph\n",
    "        self.input_data = tf.placeholder(tf.int32, [None, self.seq_length], name='input_data')\n",
    "        self.targets = tf.placeholder(tf.int32, [None, self.seq_length], name='targets')\n",
    "        self.initial_state = self.cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "        # Set Network\n",
    "        with tf.variable_scope('rnnlm')  :\n",
    "            \n",
    "            softmax_w = tf.get_variable(\"softmax_w\", [rnn_size, vocab_size])\n",
    "            softmax_b = tf.get_variable(\"softmax_b\", [vocab_size])\n",
    "            \n",
    "\n",
    "            self.embedding = vocab_embedded\n",
    "\n",
    "            inputs = tf.split(tf.nn.embedding_lookup(self.embedding, self.input_data), self.seq_length, 1)\n",
    "            inputs = [tf.squeeze(input_, [1]) for input_ in inputs]\n",
    "\n",
    "        # Output of RNN       \n",
    "        outputs, last_state = tf.contrib.legacy_seq2seq.rnn_decoder(\n",
    "            inputs, self.initial_state, self.cell, loop_function=None, scope='rnnlm')\n",
    "        output = tf.reshape(tf.concat(outputs, 1), [-1, rnn_size])\n",
    "        logits = tf.nn.xw_plus_b(output, softmax_w, softmax_b)\n",
    "\n",
    "        # Next word probability\n",
    "        self.probs = tf.nn.softmax(logits)\n",
    "\n",
    "        # Define LOSS\n",
    "        loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([logits],  # Input\n",
    "                                                                  [tf.reshape(self.targets, [-1])],  # Target\n",
    "                                                                  [tf.ones([self.batch_size * self.seq_length])],  # Weight\n",
    "                                                                  self.vocab_size)\n",
    "\n",
    "        # Define Optimizer\n",
    "        self.cost = tf.reduce_sum(loss) / self.batch_size / self.seq_length\n",
    "        tf.summary.scalar(\"cost\", self.cost)\n",
    "\n",
    "        self.final_state = last_state\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(self.cost, tvars), grad_clip)\n",
    "\n",
    "        # for weight decay\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        learning_rate = tf.train.exponential_decay(start_learning_rate, global_step, decay_step, decay_rate, staircase=False)\n",
    "        tf.summary.scalar(\"learning_rate\", learning_rate)\n",
    "\n",
    "        self.optm = tf.train.AdamOptimizer(learning_rate).apply_gradients(zip(grads, tvars))\n",
    "\n",
    "        self.merged = tf.summary.merge_all()\n",
    "\n",
    "        # make directories\n",
    "        if not os.path.exists(MODEL_PATH):\n",
    "            os.mkdir(MODEL_PATH)\n",
    "\n",
    "        if not os.path.exists(LOGS_PATH):\n",
    "            os.mkdir(LOGS_PATH)\n",
    "\n",
    "        # init session\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # saver\n",
    "        self.saver = tf.train.Saver(tf.global_variables())\n",
    "        self.summary_writer = tf.summary.FileWriter(LOGS_PATH, graph=self.sess.graph)\n",
    "\n",
    "    def restore(self):\n",
    "        latest_checkpoint = self.tf.train.latest_checkpoint(MODEL_PATH)\n",
    "\n",
    "        if not latest_checkpoint:\n",
    "            print(\"Trained network not found on \", MODEL_PATH)\n",
    "            return False\n",
    "        \n",
    "        self.saver.restore(self.sess, latest_checkpoint)\n",
    "        return True\n",
    "\n",
    "    def save(self, step):\n",
    "        checkpoint_path = os.path.join(MODEL_PATH, 'model.ckpt')\n",
    "        self.saver.save(self.sess, checkpoint_path, global_step=step)\n",
    "        print(\"model saved to {}\".format(checkpoint_path))\n",
    "        \n",
    "    def get_state(self):\n",
    "        return self.sess.run(self.initial_state)\n",
    "\n",
    "    def train(self, x, y, last_state, step):\n",
    "        train_loss, state, _, summary = self.sess.run(\n",
    "            [self.cost, self.final_state, self.optm, self.merged], {\n",
    "                self.input_data: x,\n",
    "                self.targets: y,\n",
    "                self.initial_state: last_state\n",
    "            })\n",
    "        self.summary_writer.add_summary(summary, step)\n",
    "        return train_loss, state\n",
    "\n",
    "    # Sampling function\n",
    "    \n",
    "    def sample(self, prime):\n",
    "        state = self.sess.run(self.cell.zero_state(1, self.tf.float32))\n",
    "        \n",
    "        prime_list = list(prime)\n",
    "        if len(prime_list) != self.seq_length :\n",
    "            while len(prime_list) != self.seq_length:\n",
    "                prime_list.append('<eos>')\n",
    "\n",
    "        x = np.zeros((1, self.seq_length)).tolist()[0]\n",
    "        for i, char in enumerate(prime_list):\n",
    "            x[i] = vocab_dict[char]\n",
    "        x = [x]\n",
    "        feed = {self.input_data: x, self.initial_state: state}\n",
    "        [state] = self.sess.run([self.final_state], feed)\n",
    "        \n",
    "\n",
    "        \n",
    "        def weighted_pick(weight):\n",
    "            t = np.cumsum(weight)\n",
    "            s = np.sum(weight)\n",
    "            return int(np.searchsorted(t, np.random.rand(1) * s))\n",
    "            \n",
    "        pred = ''\n",
    "        x = np.zeros((1, self.seq_length)).tolist()[0]\n",
    "        for n in range(len(prime_list)):\n",
    "            x[n] = vocab_dict[prime_list[n]]\n",
    "        x = [x]\n",
    "        feed = {self.input_data: x, self.initial_state: state}\n",
    "        \n",
    "        [_probsval, state] = self.sess.run([self.probs, self.final_state], feed)\n",
    "        \n",
    "        sample_list = []\n",
    "            # sample = int(np.random.choice(len(p), p=p))\n",
    "        for pro in _probsval:\n",
    "            sample_list.append(weighted_pick(pro))\n",
    "            \n",
    "        for sample in sample_list:\n",
    "            pred += inv_vocab.get(sample)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "from tqdm import trange\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Ready\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.002\n",
    "DECAY_STEP = num_batches\n",
    "DECAY_RATE = 0.97\n",
    "DROPOUT_RATE = 0.3\n",
    "\n",
    "\n",
    "\n",
    "net = chosungRNN(tf, batch_size, seq_length, vocab_size, vocab_embedded, LEARNING_RATE, num_batches, DECAY_RATE, DROPOUT_RATE, True)\n",
    "print(\"Network Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosung_data = jaeum_part\n",
    "full_data = full_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/12500 (epoch 0), train_loss = 1.19744623\n",
      "model saved to small models/model.ckpt\n",
      "100/12500 (epoch 0), train_loss = 0.77311051\n",
      "model saved to small models/model.ckpt\n",
      "200/12500 (epoch 0), train_loss = 0.78535289\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 1/50 [06:03<4:56:45, 363.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/12500 (epoch 1), train_loss = 1.02527857\n",
      "model saved to small models/model.ckpt\n",
      "350/12500 (epoch 1), train_loss = 0.70082772\n",
      "model saved to small models/model.ckpt\n",
      "450/12500 (epoch 1), train_loss = 0.68719113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 2/50 [12:03<4:49:13, 361.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/12500 (epoch 2), train_loss = 0.90496492\n",
      "model saved to small models/model.ckpt\n",
      "600/12500 (epoch 2), train_loss = 0.62591004\n",
      "model saved to small models/model.ckpt\n",
      "700/12500 (epoch 2), train_loss = 0.60564911\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 3/50 [18:04<4:43:12, 361.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/12500 (epoch 3), train_loss = 0.77921605\n",
      "model saved to small models/model.ckpt\n",
      "850/12500 (epoch 3), train_loss = 0.56179184\n",
      "model saved to small models/model.ckpt\n",
      "950/12500 (epoch 3), train_loss = 0.54325956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 4/50 [24:05<4:36:58, 361.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/12500 (epoch 4), train_loss = 0.68779165\n",
      "model saved to small models/model.ckpt\n",
      "1100/12500 (epoch 4), train_loss = 0.51792514\n",
      "model saved to small models/model.ckpt\n",
      "1200/12500 (epoch 4), train_loss = 0.48800892\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 5/50 [30:07<4:31:09, 361.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/12500 (epoch 5), train_loss = 0.63285434\n",
      "model saved to small models/model.ckpt\n",
      "1350/12500 (epoch 5), train_loss = 0.47895211\n",
      "model saved to small models/model.ckpt\n",
      "1450/12500 (epoch 5), train_loss = 0.44274560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 6/50 [36:09<4:25:06, 361.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/12500 (epoch 6), train_loss = 0.56934166\n",
      "model saved to small models/model.ckpt\n",
      "1600/12500 (epoch 6), train_loss = 0.44258857\n",
      "model saved to small models/model.ckpt\n",
      "1700/12500 (epoch 6), train_loss = 0.40833658\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 7/50 [42:12<4:19:15, 361.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750/12500 (epoch 7), train_loss = 0.52747589\n",
      "model saved to small models/model.ckpt\n",
      "1850/12500 (epoch 7), train_loss = 0.38916790\n",
      "model saved to small models/model.ckpt\n",
      "1950/12500 (epoch 7), train_loss = 0.36556458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 8/50 [48:12<4:13:06, 361.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/12500 (epoch 8), train_loss = 0.46334705\n",
      "model saved to small models/model.ckpt\n",
      "2100/12500 (epoch 8), train_loss = 0.36826983\n",
      "model saved to small models/model.ckpt\n",
      "2200/12500 (epoch 8), train_loss = 0.32630584\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 9/50 [54:15<4:07:09, 361.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/12500 (epoch 9), train_loss = 0.42664513\n",
      "model saved to small models/model.ckpt\n",
      "2350/12500 (epoch 9), train_loss = 0.32350212\n",
      "model saved to small models/model.ckpt\n",
      "2450/12500 (epoch 9), train_loss = 0.28540510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 10/50 [1:00:16<4:01:05, 361.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/12500 (epoch 10), train_loss = 0.38986403\n",
      "model saved to small models/model.ckpt\n",
      "2600/12500 (epoch 10), train_loss = 0.31554511\n",
      "model saved to small models/model.ckpt\n",
      "2700/12500 (epoch 10), train_loss = 0.28582078\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 11/50 [1:06:18<3:55:07, 361.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2750/12500 (epoch 11), train_loss = 0.36829439\n",
      "model saved to small models/model.ckpt\n",
      "2850/12500 (epoch 11), train_loss = 0.31071883\n",
      "model saved to small models/model.ckpt\n",
      "2950/12500 (epoch 11), train_loss = 0.28601691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 12/50 [1:12:21<3:49:06, 361.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/12500 (epoch 12), train_loss = 0.32183453\n",
      "model saved to small models/model.ckpt\n",
      "3100/12500 (epoch 12), train_loss = 0.28318435\n",
      "model saved to small models/model.ckpt\n",
      "3200/12500 (epoch 12), train_loss = 0.26011452\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 13/50 [1:18:23<3:43:08, 361.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3250/12500 (epoch 13), train_loss = 0.30312836\n",
      "model saved to small models/model.ckpt\n",
      "3350/12500 (epoch 13), train_loss = 0.25097889\n",
      "model saved to small models/model.ckpt\n",
      "3450/12500 (epoch 13), train_loss = 0.23809037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 14/50 [1:24:24<3:37:04, 361.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500/12500 (epoch 14), train_loss = 0.32985646\n",
      "model saved to small models/model.ckpt\n",
      "3600/12500 (epoch 14), train_loss = 0.23538378\n",
      "model saved to small models/model.ckpt\n",
      "3700/12500 (epoch 14), train_loss = 0.23743911\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 15/50 [1:30:28<3:31:05, 361.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3750/12500 (epoch 15), train_loss = 0.28832614\n",
      "model saved to small models/model.ckpt\n",
      "3850/12500 (epoch 15), train_loss = 0.22629273\n",
      "model saved to small models/model.ckpt\n",
      "3950/12500 (epoch 15), train_loss = 0.22380094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 16/50 [1:36:29<3:25:02, 361.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/12500 (epoch 16), train_loss = 0.27126309\n",
      "model saved to small models/model.ckpt\n",
      "4100/12500 (epoch 16), train_loss = 0.20238519\n",
      "model saved to small models/model.ckpt\n",
      "4200/12500 (epoch 16), train_loss = 0.22841282\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 17/50 [1:42:32<3:19:03, 361.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4250/12500 (epoch 17), train_loss = 0.25041214\n",
      "model saved to small models/model.ckpt\n",
      "4350/12500 (epoch 17), train_loss = 0.20021112\n",
      "model saved to small models/model.ckpt\n",
      "4450/12500 (epoch 17), train_loss = 0.20009813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 18/50 [1:48:40<3:13:11, 362.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500/12500 (epoch 18), train_loss = 0.23645195\n",
      "model saved to small models/model.ckpt\n",
      "4600/12500 (epoch 18), train_loss = 0.19297153\n",
      "model saved to small models/model.ckpt\n",
      "4700/12500 (epoch 18), train_loss = 0.19060709\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 19/50 [1:54:44<3:07:13, 362.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4750/12500 (epoch 19), train_loss = 0.21532083\n",
      "model saved to small models/model.ckpt\n",
      "4850/12500 (epoch 19), train_loss = 0.19356520\n",
      "model saved to small models/model.ckpt\n",
      "4950/12500 (epoch 19), train_loss = 0.19005409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 20/50 [2:00:47<3:01:10, 362.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/12500 (epoch 20), train_loss = 0.24345422\n",
      "model saved to small models/model.ckpt\n",
      "5100/12500 (epoch 20), train_loss = 0.17853948\n",
      "model saved to small models/model.ckpt\n",
      "5200/12500 (epoch 20), train_loss = 0.17424479\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 21/50 [2:06:50<2:55:10, 362.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5250/12500 (epoch 21), train_loss = 0.22897574\n",
      "model saved to small models/model.ckpt\n",
      "5350/12500 (epoch 21), train_loss = 0.17815046\n",
      "model saved to small models/model.ckpt\n",
      "5450/12500 (epoch 21), train_loss = 0.18845694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 22/50 [2:12:53<2:49:07, 362.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500/12500 (epoch 22), train_loss = 0.20496888\n",
      "model saved to small models/model.ckpt\n",
      "5600/12500 (epoch 22), train_loss = 0.16948380\n",
      "model saved to small models/model.ckpt\n",
      "5700/12500 (epoch 22), train_loss = 0.18316101\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 23/50 [2:18:58<2:43:08, 362.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5750/12500 (epoch 23), train_loss = 0.22280367\n",
      "model saved to small models/model.ckpt\n",
      "5850/12500 (epoch 23), train_loss = 0.15793326\n",
      "model saved to small models/model.ckpt\n",
      "5950/12500 (epoch 23), train_loss = 0.17730518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 24/50 [2:25:00<2:37:05, 362.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/12500 (epoch 24), train_loss = 0.21716996\n",
      "model saved to small models/model.ckpt\n",
      "6100/12500 (epoch 24), train_loss = 0.14862649\n",
      "model saved to small models/model.ckpt\n",
      "6200/12500 (epoch 24), train_loss = 0.16211957\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 25/50 [2:31:04<2:31:04, 362.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/12500 (epoch 25), train_loss = 0.21113443\n",
      "model saved to small models/model.ckpt\n",
      "6350/12500 (epoch 25), train_loss = 0.13867119\n",
      "model saved to small models/model.ckpt\n",
      "6450/12500 (epoch 25), train_loss = 0.15560378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 26/50 [2:37:06<2:25:01, 362.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500/12500 (epoch 26), train_loss = 0.22324948\n",
      "model saved to small models/model.ckpt\n",
      "6600/12500 (epoch 26), train_loss = 0.14982685\n",
      "model saved to small models/model.ckpt\n",
      "6700/12500 (epoch 26), train_loss = 0.16128103\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 27/50 [2:43:09<2:18:59, 362.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6750/12500 (epoch 27), train_loss = 0.21132500\n",
      "model saved to small models/model.ckpt\n",
      "6850/12500 (epoch 27), train_loss = 0.14780688\n",
      "model saved to small models/model.ckpt\n",
      "6950/12500 (epoch 27), train_loss = 0.15587822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 28/50 [2:49:12<2:12:56, 362.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/12500 (epoch 28), train_loss = 0.19343670\n",
      "model saved to small models/model.ckpt\n",
      "7100/12500 (epoch 28), train_loss = 0.15136805\n",
      "model saved to small models/model.ckpt\n",
      "7200/12500 (epoch 28), train_loss = 0.13867824\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 29/50 [2:55:15<2:06:54, 362.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7250/12500 (epoch 29), train_loss = 0.21129784\n",
      "model saved to small models/model.ckpt\n",
      "7350/12500 (epoch 29), train_loss = 0.16268542\n",
      "model saved to small models/model.ckpt\n",
      "7450/12500 (epoch 29), train_loss = 0.14512686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 30/50 [3:01:17<2:00:51, 362.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/12500 (epoch 30), train_loss = 0.20001540\n",
      "model saved to small models/model.ckpt\n",
      "7600/12500 (epoch 30), train_loss = 0.13602725\n",
      "model saved to small models/model.ckpt\n",
      "7700/12500 (epoch 30), train_loss = 0.13994892\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 31/50 [3:07:21<1:54:49, 362.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7750/12500 (epoch 31), train_loss = 0.19397788\n",
      "model saved to small models/model.ckpt\n",
      "7850/12500 (epoch 31), train_loss = 0.14268789\n",
      "model saved to small models/model.ckpt\n",
      "7950/12500 (epoch 31), train_loss = 0.13323052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 32/50 [3:13:24<1:48:47, 362.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/12500 (epoch 32), train_loss = 0.19666836\n",
      "model saved to small models/model.ckpt\n",
      "8100/12500 (epoch 32), train_loss = 0.12481406\n",
      "model saved to small models/model.ckpt\n",
      "8200/12500 (epoch 32), train_loss = 0.14387976\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 33/50 [3:19:27<1:42:45, 362.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8250/12500 (epoch 33), train_loss = 0.18903875\n",
      "model saved to small models/model.ckpt\n",
      "8350/12500 (epoch 33), train_loss = 0.12301002\n",
      "model saved to small models/model.ckpt\n",
      "8450/12500 (epoch 33), train_loss = 0.13093209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 34/50 [3:25:30<1:36:42, 362.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500/12500 (epoch 34), train_loss = 0.20492280\n",
      "model saved to small models/model.ckpt\n",
      "8600/12500 (epoch 34), train_loss = 0.13308927\n",
      "model saved to small models/model.ckpt\n",
      "8700/12500 (epoch 34), train_loss = 0.13502954\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 35/50 [3:31:34<1:30:40, 362.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8750/12500 (epoch 35), train_loss = 0.20717268\n",
      "model saved to small models/model.ckpt\n",
      "8850/12500 (epoch 35), train_loss = 0.12494143\n",
      "model saved to small models/model.ckpt\n",
      "8950/12500 (epoch 35), train_loss = 0.12989599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 36/50 [3:37:37<1:24:37, 362.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/12500 (epoch 36), train_loss = 0.20538676\n",
      "model saved to small models/model.ckpt\n",
      "9100/12500 (epoch 36), train_loss = 0.11357677\n",
      "model saved to small models/model.ckpt\n",
      "9200/12500 (epoch 36), train_loss = 0.13696979\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 37/50 [3:43:42<1:18:35, 362.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9250/12500 (epoch 37), train_loss = 0.18988010\n",
      "model saved to small models/model.ckpt\n",
      "9350/12500 (epoch 37), train_loss = 0.13950112\n",
      "model saved to small models/model.ckpt\n",
      "9450/12500 (epoch 37), train_loss = 0.14087349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 38/50 [3:49:44<1:12:32, 362.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9500/12500 (epoch 38), train_loss = 0.18120031\n",
      "model saved to small models/model.ckpt\n",
      "9600/12500 (epoch 38), train_loss = 0.11460935\n",
      "model saved to small models/model.ckpt\n",
      "9700/12500 (epoch 38), train_loss = 0.12675169\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 39/50 [3:55:48<1:06:30, 362.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9750/12500 (epoch 39), train_loss = 0.19122604\n",
      "model saved to small models/model.ckpt\n",
      "9850/12500 (epoch 39), train_loss = 0.12270683\n",
      "model saved to small models/model.ckpt\n",
      "9950/12500 (epoch 39), train_loss = 0.12977111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 40/50 [4:01:50<1:00:27, 362.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/12500 (epoch 40), train_loss = 0.19595823\n",
      "model saved to small models/model.ckpt\n",
      "10100/12500 (epoch 40), train_loss = 0.11834130\n",
      "model saved to small models/model.ckpt\n",
      "10200/12500 (epoch 40), train_loss = 0.13899647\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 41/50 [4:07:54<54:25, 362.80s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10250/12500 (epoch 41), train_loss = 0.18225223\n",
      "model saved to small models/model.ckpt\n",
      "10350/12500 (epoch 41), train_loss = 0.12323700\n",
      "model saved to small models/model.ckpt\n",
      "10450/12500 (epoch 41), train_loss = 0.13289425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 42/50 [4:13:56<48:22, 362.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500/12500 (epoch 42), train_loss = 0.18259445\n",
      "model saved to small models/model.ckpt\n",
      "10600/12500 (epoch 42), train_loss = 0.10991748\n",
      "model saved to small models/model.ckpt\n",
      "10700/12500 (epoch 42), train_loss = 0.12698407\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 43/50 [4:20:00<42:19, 362.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10750/12500 (epoch 43), train_loss = 0.18590589\n",
      "model saved to small models/model.ckpt\n",
      "10850/12500 (epoch 43), train_loss = 0.12600425\n",
      "model saved to small models/model.ckpt\n",
      "10950/12500 (epoch 43), train_loss = 0.12861094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 44/50 [4:26:03<36:16, 362.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000/12500 (epoch 44), train_loss = 0.24284308\n",
      "model saved to small models/model.ckpt\n",
      "11100/12500 (epoch 44), train_loss = 0.11954918\n",
      "model saved to small models/model.ckpt\n",
      "11200/12500 (epoch 44), train_loss = 0.11888113\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 45/50 [4:32:08<30:14, 362.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11250/12500 (epoch 45), train_loss = 0.20969169\n",
      "model saved to small models/model.ckpt\n",
      "11350/12500 (epoch 45), train_loss = 0.11684489\n",
      "model saved to small models/model.ckpt\n",
      "11450/12500 (epoch 45), train_loss = 0.11345868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 46/50 [4:38:09<24:11, 362.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11500/12500 (epoch 46), train_loss = 0.18908773\n",
      "model saved to small models/model.ckpt\n",
      "11600/12500 (epoch 46), train_loss = 0.11687814\n",
      "model saved to small models/model.ckpt\n",
      "11700/12500 (epoch 46), train_loss = 0.12353092\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 47/50 [4:44:12<18:08, 362.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11750/12500 (epoch 47), train_loss = 0.18701014\n",
      "model saved to small models/model.ckpt\n",
      "11850/12500 (epoch 47), train_loss = 0.09872959\n",
      "model saved to small models/model.ckpt\n",
      "11950/12500 (epoch 47), train_loss = 0.11455939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 48/50 [4:50:14<12:05, 362.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000/12500 (epoch 48), train_loss = 0.18621527\n",
      "model saved to small models/model.ckpt\n",
      "12100/12500 (epoch 48), train_loss = 0.10107493\n",
      "model saved to small models/model.ckpt\n",
      "12200/12500 (epoch 48), train_loss = 0.11163632\n",
      "model saved to small models/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 49/50 [4:56:19<06:02, 362.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12250/12500 (epoch 49), train_loss = 0.17872626\n",
      "model saved to small models/model.ckpt\n",
      "12350/12500 (epoch 49), train_loss = 0.11343014\n",
      "model saved to small models/model.ckpt\n",
      "12450/12500 (epoch 49), train_loss = 0.11445989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [5:02:21<00:00, 362.83s/it]\n"
     ]
    }
   ],
   "source": [
    "# Train the model!\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "SAVE_EVERY = 100\n",
    "pointer = 0\n",
    "\n",
    "x, y = create_batches(chosung_data, full_data,batch_size, seq_length)\n",
    "\n",
    "for e in trange(NUM_EPOCHS):  # for all epochs\n",
    "\n",
    "    reset_batch_pointer()\n",
    "    num_batches = int(num_batches)\n",
    "    state = net.get_state()\n",
    "    for b in range(num_batches):\n",
    "        \n",
    "        step = e * num_batches + b\n",
    "        next_x, next_y = next_batch(x, y)\n",
    "        \n",
    "        # Train!\n",
    "        train_loss, state = net.train(next_x, next_y, state, step)\n",
    "        \n",
    "        if b % 100 == 0:\n",
    "            print(\"{}/{} (epoch {}), train_loss = {:.8f}\".format(\n",
    "                step,\n",
    "                NUM_EPOCHS * num_batches,\n",
    "                e, train_loss))\n",
    "\n",
    "        if step % SAVE_EVERY == 0:\n",
    "            net.save(step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Ready\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.002\n",
    "DECAY_STEP = num_batches\n",
    "DECAY_RATE = 0.97\n",
    "DROPOUT_RATE = 0.3\n",
    "\n",
    "\n",
    "net = chosungRNN(tf, 1, seq_length, vocab_size, vocab_embedded, LEARNING_RATE, num_batches, DECAY_RATE, DROPOUT_RATE, False)\n",
    "print(\"Network Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore network from  small models/model.ckpt-12400\n",
      "INFO:tensorflow:Restoring parameters from small models/model.ckpt-12400\n",
      "\n",
      "-- RESULT --\n",
      "ㅅㅈㅎㅈ ㅁㄱ\n",
      "사주하잔 마고\n"
     ]
    }
   ],
   "source": [
    "PRIME_TEXT = 'ㅅㅈㅎㅈ ㅁㄱ'\n",
    "\n",
    "\n",
    "\n",
    "if net.restore():\n",
    "    sampled_text = net.sample(PRIME_TEXT)\n",
    "    \n",
    "    sampled_text = re.sub('\\<eos\\>', '', sampled_text)\n",
    "    print(\"\")\n",
    "    print(\"-- RESULT --\")\n",
    "    print(\"%s\" % PRIME_TEXT)\n",
    "    print(sampled_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
